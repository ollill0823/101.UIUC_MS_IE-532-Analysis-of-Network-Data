{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1c440f",
   "metadata": {
    "id": "2a1c440f"
   },
   "source": [
    "* **Courses:** Fall 2022-IE 532-Analysis of Network Data\n",
    "* **Topic:** Final Group project\n",
    "* **Student name:**  Chen Wang/JoTing Wang/SzuMin Chao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc32320",
   "metadata": {
    "id": "bfc32320"
   },
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Chapter 1: Data-preprocessing](#preprocessing)\n",
    "2. [Chapter 2: Visualization](#Visualization)\n",
    "3. [Chapter 3 : problem 1--re-arranging Taichung city's district ](#Rearrangement)\n",
    "4. [Chapter 4 : problem 2-- Gerrymandering to benefit the winner(The Dpp party)](#Dpp)\n",
    "5. [Chapter 5 : problem 3-- Gerrymandering to benefit the loser(The KMT party)](#KMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db38dd79",
   "metadata": {
    "id": "db38dd79"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'soft_unicode' from 'markupsafe' (C:\\Users\\ppwan\\anaconda3\\lib\\site-packages\\markupsafe\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfolium\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\folium\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbranca\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbranca\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolormap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ColorMap, LinearColormap, StepColormap)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbranca\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     CssLink,\n\u001b[0;32m      7\u001b[0m     Div,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     MacroElement,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\branca\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbranca\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolormap\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcolormap\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbranca\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melement\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01melement\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\branca\\colormap.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjinja2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Template\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbranca\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melement\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ENV, Figure, JavascriptLink, MacroElement\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbranca\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m legend_scaler\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\jinja2\\__init__.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbccache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileSystemBytecodeCache\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbccache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MemcachedBytecodeCache\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Environment\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Template\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TemplateAssertionError\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\jinja2\\environment.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CodeGenerator\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BLOCK_END_STRING\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BLOCK_START_STRING\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefaults\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMMENT_END_STRING\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\jinja2\\defaults.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m range_type\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FILTERS \u001b[38;5;28;01mas\u001b[39;00m DEFAULT_FILTERS  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TESTS \u001b[38;5;28;01mas\u001b[39;00m DEFAULT_TESTS  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cycler\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\jinja2\\filters.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarkupsafe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m escape\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarkupsafe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Markup\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarkupsafe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m soft_unicode\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abc\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imap\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'soft_unicode' from 'markupsafe' (C:\\Users\\ppwan\\anaconda3\\lib\\site-packages\\markupsafe\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import time\n",
    "import folium\n",
    "import glob\n",
    "import json\n",
    "import folium\n",
    "\n",
    "import matplotlib.offsetbox as offsetbox\n",
    "import networkx as nx\n",
    "from gurobipy import *\n",
    "from itertools import combinations\n",
    "import heapq as hq\n",
    "from random import sample\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b33de8",
   "metadata": {
    "id": "95b33de8"
   },
   "outputs": [],
   "source": [
    "data_color = \"red\"\n",
    "markersize = 5\n",
    "thinlinesize=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de7ca98",
   "metadata": {
    "id": "2de7ca98"
   },
   "outputs": [],
   "source": [
    "def textbox(txt,fname=None):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.gca().add_artist(offsetbox.AnchoredText(\"\\n\".join(txt), loc=\"center\",prop=dict(size=30)))\n",
    "    plt.axis('off')\n",
    "    if fname is not None:\n",
    "        saver(fname)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a349fff",
   "metadata": {
    "id": "3a349fff"
   },
   "outputs": [],
   "source": [
    "def legend(pos=\"bottom\",ncol=3,extra=False):\n",
    "    if pos==\"bottom\":\n",
    "        extra = 0.15 if extra else 0\n",
    "        plt.legend(bbox_to_anchor=(0.5,-0.2-extra), loc='upper center',facecolor=\"lightgray\",ncol=ncol)\n",
    "    elif pos==\"side\":\n",
    "        plt.legend(bbox_to_anchor=(1.1,0.5), loc='center left',facecolor=\"lightgray\",ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e96e3",
   "metadata": {
    "id": "539e96e3"
   },
   "source": [
    "### Get the file:\n",
    "1.Try to get the local file <br>\n",
    "2.If can't get the local file, try to access google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a14dbb",
   "metadata": {
    "id": "11a14dbb",
    "outputId": "46347a59-36ad-42d0-e385-3cc627571f95",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_file(location_pair, names = None, **kwargs):\n",
    "    ## Open zip file\n",
    "    if len(location_pair) == 3:\n",
    "        (loc,zipname,gdrive)=location_pair  \n",
    "        try:\n",
    "            with zipfile.ZipFile(zipname) as z:\n",
    "                with z.open(loc) as f:\n",
    "                    out = pd.read_excel(f)\n",
    "        except FileNotFoundError:\n",
    "            print(\"local file not found; accessing Google Drive\")\n",
    "            zipname = gdrive + zipname\n",
    "            with zipfile.ZipFile(zipname) as z:\n",
    "                with z.open(loc) as f:\n",
    "                    out = pd.read_excel(f, engine='openpyxl')\n",
    "    ## Open xlsx file\n",
    "    elif len(location_pair) == 2:\n",
    "        (loc,gdrive)=location_pair\n",
    "        try:\n",
    "            out= pd.read_excel(loc, engine='openpyxl')\n",
    "        except FileNotFoundError:\n",
    "            print(\"local file not found; accessing Google Drive\")\n",
    "            loc = \"https://docs.google.com/spreadsheets/d/1dognp7WSgiO0zFA0HdTn7AzUl4HEWrEw/edit?usp=share_link&ouid=117434447847034760525&rtpof=true&sd=true\"\n",
    "            out= pd.read_excel(loc)\n",
    "        \n",
    "    return out\n",
    "\n",
    "fname=(\"Taiwan_Taichung_2018_legislator_election_distribution.xlsx\", \"https://drive.google.com/drive/folders/1mNrvxv_t6OrfyhOO023cc5Bi4QPORQLX?usp=share_link\")\n",
    "Taichung = get_file(fname)\n",
    "print(Taichung.shape)\n",
    "Taichung.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fdf372",
   "metadata": {
    "id": "41fdf372"
   },
   "source": [
    "### Deal with error code:\n",
    "Base on Unicode, \\u3000 is a ideographic space, we need to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076bb181",
   "metadata": {
    "id": "076bb181",
    "outputId": "fffdf440-97fe-43d7-d2e8-44e48aed61b3"
   },
   "outputs": [],
   "source": [
    "# Need to remove the \\u3000\n",
    "Taichung[\"district\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e57850",
   "metadata": {
    "id": "59e57850"
   },
   "source": [
    "### Calculation:\n",
    "1.\"Bias\" is the difference of votes between DPP and KMT.\n",
    "<br>2.\"Sum\" is to add the votes of DPP and KMT together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca11917",
   "metadata": {
    "id": "9ca11917"
   },
   "outputs": [],
   "source": [
    "Taichung[\"district\"] = Taichung[\"district\"].apply(lambda x: x[1:])\n",
    "Taichung[\"bias\"] = Taichung[\"DPP\"] - Taichung[\"KMT\"]\n",
    "Taichung[\"sum\"] = Taichung[\"DPP\"] + Taichung[\"KMT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369688e4",
   "metadata": {
    "id": "369688e4"
   },
   "source": [
    "## Chapter 1: Data preprocessing<a name=\"preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aedf7b",
   "metadata": {
    "id": "63aedf7b"
   },
   "source": [
    "### Check missing data \n",
    "1.Use dropna to remove missing data in the postcode columns\n",
    "<br>2.Get rid of \"paon\", \"street\", \"locality\" columns because it contains useless information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da087a",
   "metadata": {
    "id": "d6da087a",
    "outputId": "2f2e0a74-bd9f-41d5-ae2b-34b9c52e2174"
   },
   "outputs": [],
   "source": [
    "Taichung.isnull().sum().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0776e5c",
   "metadata": {
    "id": "b0776e5c"
   },
   "source": [
    "### Check dataframe's keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c57463",
   "metadata": {
    "id": "18c57463",
    "outputId": "b2bd96b8-c473-4524-b2a2-361671edec92"
   },
   "outputs": [],
   "source": [
    "Taichung.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281de3ea",
   "metadata": {
    "id": "281de3ea",
    "outputId": "0e244de3-dd0a-4707-ed6f-098faa09eee9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Taichung.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1a554",
   "metadata": {
    "id": "a3b1a554"
   },
   "source": [
    "### Modify the data type to (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a2645",
   "metadata": {
    "id": "f22a2645",
    "outputId": "37887fa7-6ff8-42ac-837e-51d39676b140",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Taichung[\"legislator_district\"] = Taichung[\"legislator_district\"].astype(str)\n",
    "Taichung.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d37cb9",
   "metadata": {
    "id": "68d37cb9"
   },
   "source": [
    "### Get Taichung_by_legislator_district aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbee9df",
   "metadata": {
    "id": "8dbee9df",
    "outputId": "b99058f4-208b-4b3f-cae6-fea225349f8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Extract \\033[1m\\033[91mTaichung_by_legislator_district\\033[0m from the Pickle folder.\\n\")\n",
    "    Taichung_by_legislator_district = pd.read_pickle(\"Pickle/Taichung_by_legislator_district.pkl\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\033[1m\\033[91mDid not\\033[0m find the file from pickle file. Extract data from the aggregation.\\n\")\n",
    "    \n",
    "    Taichung_by_legislator_district = Taichung.groupby(\"legislator_district\").sum()\n",
    "    Taichung_by_legislator_district = Taichung_by_legislator_district.reset_index()\n",
    "    \n",
    "    Taichung_by_legislator_district.to_pickle(\"Pickle/Taichung_by_legislator_district.pkl\") \n",
    "\n",
    "print(\"Get Taichung_by_legislator_district file \\033[1m\\033[94mready\\033[0m.\\n\")\n",
    "Taichung_by_legislator_district.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d5485",
   "metadata": {
    "id": "1c3d5485",
    "outputId": "3ea23226-703f-4fbd-bf33-e0b601de05e7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Taichung_by_legislator_district aggregation\n",
    "try:\n",
    "    print(\"Extract \\033[1m\\033[91mTaichung_by_district file \\033[0m from the pickle folder.\")\n",
    "    Taichung_by_district = pd.read_pickle(\"Pickle/Taichung_by_district.pkl\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\033[1m\\033[91mDid not\\033[0m find the file from pickle file. Extract data from the aggregation.\")\n",
    "    \n",
    "    Taichung_by_district = Taichung.groupby(\"district\").sum()\n",
    "    Taichung_by_district = Taichung_by_district.reset_index()\n",
    "    Taichung_by_district = Taichung_by_district.rename_axis('node').reset_index()\n",
    "    Taichung_by_district = pd.merge(Taichung_by_district, Taichung.iloc[:,0:2].drop_duplicates(), on = \"district\", how = \"left\")\n",
    "    \n",
    "    \n",
    "    ## Translate Chinese district names into English\n",
    "    translation2 = {'中區': 'Central Dist.', '北區': 'North Dist.', '北屯區': 'Beitun Dist.', '南區': 'South Dist.', \n",
    "                '南屯區': 'Nantun Dist.', '后里區': 'Houli Dist.', '和平區': 'Heping Dist.', '外埔區': 'Waipu Dist.', \n",
    "                '大安區': 'Daan Dist.', '大甲區': 'Dajia Dist.', '大肚區': 'Dadu Dist.', '大里區': 'Dali Dist.', \n",
    "                '大雅區': 'Daya Dist.', '太平區': 'Taiping Dist.', '新社區': 'Xinshe Dist.', '東勢區': 'Dongshi Dist.', \n",
    "                '東區': 'East Dist.', '梧棲區': 'Wuqi Dist.', '沙鹿區': 'Shalu Dist.', '清水區': 'Qingshui Dist.', \n",
    "                '潭子區': 'Tanzi Dist.', '烏日區': 'Wuri Dist.', '石岡區': 'Shigang Dist.', '神岡區': 'Shengang Dist.',\n",
    "                '西區': 'West Dist.', '西屯區': 'Xitun Dist.', '豐原區': 'Fongyuan Dist.', '霧峰區': 'WuFong Dist.', \n",
    "                '龍井區': 'Longjing Dist.'}\n",
    "    Taichung_by_district[\"translation\"] = 0\n",
    "    for i in range(Taichung_by_district.shape[0]):\n",
    "        Taichung_by_district[\"translation\"][i] = translation2[Taichung_by_district[\"district\"][i]]\n",
    "        \n",
    "    Taichung_by_district[\"district2\"] = Taichung_by_district[\"district\"]\n",
    "    Taichung_by_district =  Taichung_by_district.set_index('district2')    \n",
    "    \n",
    "    \n",
    "    Taichung_by_district.to_pickle(\"Pickle/Taichung_by_district.pkl\") \n",
    "\n",
    "print(\"Get Taichung_by_district file \\033[1m\\033[94mready\\033[0m.\")\n",
    "Taichung_by_district.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c1759e",
   "metadata": {
    "id": "d4c1759e"
   },
   "source": [
    "### Geojson file:\n",
    "1.Downloaded the geojson file from https://github.com/missinglink/uk-postcode-polygons/tree/master/geojson\n",
    "<br>2.Merge multi geojson files to one file for map drawing.\n",
    "<br><br>*Files merging reference: https://blog.csdn.net/Ssbusbusbsubs/article/details/114855353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce09d2",
   "metadata": {
    "id": "42ce09d2",
    "outputId": "cbef5cb4-6e38-4ce3-8601-6ccc85883cad"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Check if Geo_json_file folder exists \\033[1m\\033[91mTaichung_json.json file\\033[0m.\")\n",
    "    Taichung_json = json.load(open(\"Geo_json_file/Taichung_json.json\", \"r\"))\n",
    "    print(\"\\033[1m\\033[94mHave found\\033[0m Taichung_json.json file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\033[1m\\033[91mDid not\\033[0m find Taichung_json.json file. Extract Taichung json file from \\033[1m\\033[95mTaiwan-village-boundaries.json\\033[0m\")\n",
    "    Taiwan_geojson = json.load(open(\"Geo_json_file/Taiwan-village-boundaries.json\", \"r\"))\n",
    "    Taichung_json = Taiwan_geojson.copy()\n",
    "    Taichung_json[\"features\"] = []\n",
    "    for i in range(len(Taiwan_geojson[\"features\"])):\n",
    "        if Taiwan_geojson[\"features\"][i][\"properties\"][\"C_Name\"] == \"臺中市\":\n",
    "            Taichung_json[\"features\"].append(Taiwan_geojson[\"features\"][i])\n",
    "            \n",
    "    # Output the combination of Taichung_json.json file.            \n",
    "    with open(\"Geo_json_file/Taichung_json.json\", \"w\", encoding = \"utf-8\") as outfile:\n",
    "        json.dump(Taichung_json, outfile, ensure_ascii = False)\n",
    "\n",
    "print(\"Get Taichung_json.json file \\033[1m\\033[94mready\\033[0m.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c51f3",
   "metadata": {
    "id": "002c51f3"
   },
   "source": [
    "## Chapter 2: Visualization<a name=\"Visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c71fd",
   "metadata": {
    "id": "999c71fd"
   },
   "outputs": [],
   "source": [
    "data = Taichung_by_district.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d5e76e",
   "metadata": {
    "id": "17d5e76e",
    "outputId": "129c5a3c-ea77-46c4-c37f-32cfcbb8f0d6"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c47848",
   "metadata": {
    "id": "43c47848"
   },
   "source": [
    "### Start mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ee35b",
   "metadata": {
    "id": "fc7ee35b",
    "outputId": "9f76b07b-72e9-4b66-a8aa-5ff896ddbc34",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mapping scale. Define the scale into ten divisions\n",
    "custom_scale = (data['bias'].quantile((0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1))).tolist()\n",
    "\n",
    "# Create a map and define its location, map formation, and plotting scale\n",
    "m = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "# Mapping parameters\n",
    "cp = folium.Choropleth(\n",
    "    data=data,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='PRGn',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    threshold_scale=custom_scale,\n",
    "    columns=['district', 'bias'],   \n",
    "    legend_name='2018 Taichung legislation distribution',\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", ]).add_to(cp.geojson)\n",
    "\n",
    "  \n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04e68f9",
   "metadata": {
    "id": "c04e68f9",
    "outputId": "e87a116c-1075-4d41-f17c-b12e84878f43"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe380f6",
   "metadata": {
    "id": "6fe380f6",
    "outputId": "b67a7a33-2567-43e9-f47e-e40eac1f37a8"
   },
   "outputs": [],
   "source": [
    "cp.geojson.data['features'][0][\"properties\"][\"T_Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f129e",
   "metadata": {
    "id": "133f129e",
    "outputId": "4e23217d-6693-48c1-b966-fcb89fef3ce5"
   },
   "outputs": [],
   "source": [
    "for s in cp.geojson.data['features']:\n",
    "    print(s)\n",
    "#     s['properties']['bias'] = str(data.loc[s[\"properties\"][\"T_Name\"], 'bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0526ac8",
   "metadata": {
    "id": "a0526ac8",
    "outputId": "bfe0295b-dd47-4ac7-a029-d057cdc71218"
   },
   "outputs": [],
   "source": [
    "cp.geojson.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea485ab",
   "metadata": {
    "id": "bea485ab"
   },
   "source": [
    "## Chapter 3 : problem 1-- re-arranging Taichung city's district<a name=\"Rearrangement\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e00000",
   "metadata": {
    "id": "b4e00000"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a65e3",
   "metadata": {
    "id": "ed3a65e3"
   },
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "node_tuple = [(0,1),(0,3),(0,16),(0,24),(1,2),(1,13),(1,16),(1,24),(1,25),(2,12),(2,13),(2,14),(2,20),(2,25),(2,26),\n",
    "              (3,4),(3,11),(3,16),(3,21),(3,24),(4,10),(4,21),(4,24),(4,25),(5,7),(5,15),(5,19),(5,23),(5,26),\n",
    "              (6,14),(6,15),(7,9),(7,19),(7,23),(8,9),(8,19),(9,19),(10,21),(10,25),(10,28),(11,13),(11,16),(11,21),(11,27),\n",
    "              (12,18),(12,19),(12,20),(12,23),(12,25),(13,14),(13,16),(13,27),(14,15),(14,22),(14,26),(15,22),(15,26),(16,24),\n",
    "              (17,18),(17,19),(17,28),(18,19),(18,23),(18,25),(18,28),(19,23),(20,23),(20,26),(21,27),(22,26),(23,26),\n",
    "              (24,25),(25,28)]\n",
    "G.add_edges_from(node_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd14e0",
   "metadata": {
    "id": "a6bd14e0",
    "outputId": "1a4bee5e-35e6-4cc3-c89c-1aaefd6bd6b6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos=nx.spring_layout(G)\n",
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f258e7",
   "metadata": {
    "id": "c9f258e7"
   },
   "outputs": [],
   "source": [
    "for i,d in G.nodes(data = True):\n",
    "    for j in range(data.shape[0]):\n",
    "        if data.iloc[j,0] == i: ## if data node equal to the G.node\n",
    "            d[\"sum\"] = data.iloc[j,5]\n",
    "            d[\"bias\"] = data.iloc[j,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d531c",
   "metadata": {
    "id": "333d531c",
    "outputId": "55bec575-53de-46be-984e-ab782d3b1382"
   },
   "outputs": [],
   "source": [
    "k_district=7\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.3\n",
    "print(avg_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb689db",
   "metadata": {
    "id": "2bb689db"
   },
   "outputs": [],
   "source": [
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc28417",
   "metadata": {
    "id": "bfc28417"
   },
   "source": [
    "#### Define variables:\n",
    "\n",
    "$$\\text{Define}~~y_{i,j} ~\\forall \\left(i,j\\right)\\in V$$\n",
    "$$y_{i,i} \\in\\left\\{0,1\\right\\}  \\text{{1, if parcel i is the center of the nodes, 0, others}}$$\n",
    "$$y_{i,j} \\in\\left\\{0,1\\right\\}  \\text{{1, if parcel i is assigned to parcel j, 0, others}}$$\n",
    "\n",
    "Reminding: directed path $y_{ij}$ (respectively, $y_{ji}$) means **from i to j (respectively from j to i)** can not be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ffe6c",
   "metadata": {
    "id": "162ffe6c"
   },
   "outputs": [],
   "source": [
    "model = Model(\"Taichung_re-distribution\")\n",
    "y_edges = {}\n",
    "\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e47afe",
   "metadata": {
    "id": "c7e47afe"
   },
   "source": [
    "#### Define constraint:\n",
    "\n",
    "$$~~\\sum_{i\\in V} y_{ii} = k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe88cf",
   "metadata": {
    "id": "aefe88cf",
    "outputId": "e5a57e41-9dad-4156-cb0f-897d05a11c63"
   },
   "outputs": [],
   "source": [
    "# Add constraint xii\n",
    "expr = 0\n",
    "for center in G.nodes():\n",
    "    expr += y_edges[(center,center)]\n",
    "model.addConstr(expr == k_district)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adecaa3e",
   "metadata": {
    "id": "adecaa3e"
   },
   "source": [
    "#### Define constraint:\n",
    "\n",
    "$$~~\\sum_{i\\in V,j\\in V} y_{ij} = 1 \\text{(from i to j)}$$\n",
    "\n",
    "Reminding: \n",
    "Control i, changing j node, there will have 4 conditions:\n",
    "<blockquote>\n",
    "    <b> Condition1:</b> if <b>i</b> is a center node, and <b>j1</b> is a center node: \n",
    "    $$ y_{ii} = 1, y_{ij_{1}} = 0 $$\n",
    "    <b> Condition2:</b> if <b>i</b> is a center node, and <b>j2</b> is a edge node: \n",
    "    $$ y_{ij_{2}} = 0 $$\n",
    "    Therefore, combined <b>Condition1</b> and <b>Condition2</b>:\n",
    "    $$~~\\sum_{i\\in V,j\\in V} y_{ij} = y_{ii} + y_{ij_{1}} + y_{ij_{2}}+.... = 1 \\text{(i is a center node)}$$\n",
    "    <b> Condition3:</b> if <b>i</b> is a edge node, and <b>j1</b> is a center node: \n",
    "    $$ y_{ii} = 0, y_{ij_{1}} = 1$$\n",
    "    <b> Condition4:</b> if <b>i</b> is a edge node, and <b>j2</b> is a edge node: \n",
    "    $$ y_{ij_{2}} = 0 $$\n",
    "    Therefore, combined <b>Condition3</b> and <b>Condition4</b>:\n",
    "    $$~~\\sum_{i\\in V,j\\in V} y_{ij} = y_{ii} + y_{ij_{1}} + y_{ij_{2}}+.... = 1 \\text{(i is a edge node)}$$\n",
    "<blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0161a9",
   "metadata": {
    "id": "cb0161a9"
   },
   "outputs": [],
   "source": [
    "for center in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for edge in G.nodes():\n",
    "            tail_to_head += y_edges[(center,edge)]\n",
    "    model.addConstr(tail_to_head == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7fb6c",
   "metadata": {
    "id": "96f7fb6c"
   },
   "source": [
    "#### Define constraint:\n",
    "\n",
    "$$~~\\sum_{i\\in V,j\\in V} y_{ij} \\leq y_{jj} \\text{(from i to j)}$$\n",
    "\n",
    "Reminding: \n",
    "Control j, changing i node, there will have 4 conditions:\n",
    "<blockquote>\n",
    "    <b> Condition1:</b> if <b>i1</b> is a center node, and <b>j</b> is a center node: \n",
    "    $$ y_{i_{1}j} = 0, y_{jj} = 1 $$\n",
    "    <b> Condition2:</b> if <b>i2</b> is a edge node, and <b>j</b> is a center node: \n",
    "    $$ y_{i_{2}j} = 1 $$\n",
    "    Therefore, combined <b>Condition1</b> and <b>Condition2</b>:\n",
    "    $$~~ 0 = y_{i_{1}j} = y_{i_{3}j} = .... \\leq y_{i_{2}j} = y_{jj} = 1 \\text{(j is a center node)}$$\n",
    "    <b> Condition3:</b> <b>i</b> is a center node, and <b>j</b> is a edge node: \n",
    "    $$ y_{i_{1}j} = 0, y_{jj} = 0 $$\n",
    "    <b> Condition4:</b> <b>i2</b> is a edge node, and <b>j</b> is a edge node: \n",
    "    $$ y_{i_{2}j} = 0 $$\n",
    "    Therefore, combined <b>Condition3</b> and <b>Condition4</b>:\n",
    "    $$~~ y_{i_{1}j} = y_{i_{3}j} = .... = y_{i_{2}j} = y_{jj} = 0 \\text{(j is a edge node)}$$\n",
    "<blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdba03c",
   "metadata": {
    "id": "9bdba03c"
   },
   "outputs": [],
   "source": [
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119ac0f",
   "metadata": {
    "id": "2119ac0f"
   },
   "source": [
    "#### Define constraint:\n",
    "Reminding: \n",
    "Control j, changing i node, summarize the distance (because distance is located at node j)\n",
    "$$~~\\sum_{i\\in V, j\\in V} y_{ij}distance_{i} \\leq (\\frac{population}{k_{district}})( 1 + tolerance)y_{jj}$$ \n",
    "$$~~\\sum_{i\\in V, j\\in V} y_{ij}distance_{i} \\geq (\\frac{population}{k_{district}})( 1 - tolerance)y_{jj}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576e41b",
   "metadata": {
    "id": "0576e41b"
   },
   "outputs": [],
   "source": [
    "# Add constraint xii\n",
    "for j in G.nodes():\n",
    "    summary = 0\n",
    "    for i,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(i,j)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(j,j)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(j,j)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285497d",
   "metadata": {
    "id": "5285497d"
   },
   "source": [
    "#### Define objective function:\n",
    "Reminding: \n",
    "summarize the shortest path from i to j \n",
    "$$\\text{min}~~\\sum_{i\\in V, j\\in V} y_{ij}distance_{i,j} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958c472",
   "metadata": {
    "id": "3958c472"
   },
   "outputs": [],
   "source": [
    "obj = 0\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        obj += distance[(i,j)]*y_edges[(i,j)]\n",
    "model.setObjective(obj, GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce6b1a",
   "metadata": {
    "id": "a8ce6b1a",
    "outputId": "4f19b2cc-0713-4c3c-fe22-399aa61606aa"
   },
   "outputs": [],
   "source": [
    "model.write(\"test2.lp\")\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a2d2f",
   "metadata": {
    "id": "3d8a2d2f",
    "outputId": "ae5a25bd-adba-4f48-d17c-6af6850dfa07"
   },
   "outputs": [],
   "source": [
    "obj.getValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7832e0d",
   "metadata": {
    "id": "b7832e0d",
    "outputId": "d8ee48b0-341b-4e1e-dc03-88f12eff0a7f"
   },
   "outputs": [],
   "source": [
    "cluster_group = {}\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].X == 1:\n",
    "        cluster_group[center] = []\n",
    "#         cluster_group[j].append(j)\n",
    "        print(y_edges[(center,center)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f6446",
   "metadata": {
    "id": "8a5f6446",
    "outputId": "d34a37ea-ed75-4163-f465-6df8af712684"
   },
   "outputs": [],
   "source": [
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].X == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            print(y_edges[(edge,center)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d666e7",
   "metadata": {
    "id": "75d666e7",
    "outputId": "7c295dce-ed2c-4a0a-98f1-b7aec105a101"
   },
   "outputs": [],
   "source": [
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop    \n",
    "summary_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f685134",
   "metadata": {
    "id": "4f685134",
    "outputId": "af1b24bc-e213-4b4c-9abd-32f8cc6b11b7"
   },
   "outputs": [],
   "source": [
    "cluster_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e524961",
   "metadata": {
    "id": "6e524961",
    "outputId": "afa31136-d016-439b-dac1-c4146e67bd7a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7051a1",
   "metadata": {
    "id": "4e7051a1"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a51d0",
   "metadata": {
    "id": "fb2a51d0",
    "outputId": "82ee2f35-986d-480d-c0c2-fe6707494826",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "m7 = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp7 = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m7)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp7.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp7.geojson)\n",
    "\n",
    "  \n",
    "m7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6242e6",
   "metadata": {
    "id": "9e6242e6"
   },
   "source": [
    "### k_district = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554fb7f",
   "metadata": {
    "id": "e554fb7f",
    "outputId": "13b149b2-99e0-4ea6-ba8e-d436f8c04421",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_district=8\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.5\n",
    "\n",
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)\n",
    "        \n",
    "model = Model(\"Taichung_re-distribution\")\n",
    "y_edges = {}\n",
    "\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')\n",
    "        \n",
    "# Add constraint yii\n",
    "expr = 0\n",
    "for center in G.nodes():\n",
    "    expr += y_edges[(center,center)]\n",
    "model.addConstr(expr == k_district)\n",
    "\n",
    "for center in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for edge in G.nodes():\n",
    "            tail_to_head += y_edges[(center,edge)]\n",
    "    model.addConstr(tail_to_head == 1)\n",
    "    \n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])\n",
    "            \n",
    "# Add constraint xii\n",
    "for center in G.nodes():\n",
    "    summary = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(edge,center)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(center,center)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(center,center)])\n",
    "    \n",
    "obj = 0\n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        obj += distance[(edge,cneter)]*y_edges[(edge,center)]\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "cluster_group = {}\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].x == 1:\n",
    "        cluster_group[center] = []\n",
    "    \n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].x == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            \n",
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f120d1",
   "metadata": {
    "id": "f4f120d1",
    "outputId": "353f7b13-7239-4764-944a-425809c1cd7e"
   },
   "outputs": [],
   "source": [
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)\n",
    "    \n",
    "cluster_group.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bf4d0",
   "metadata": {
    "id": "980bf4d0"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab3057",
   "metadata": {
    "id": "56ab3057",
    "outputId": "9ad8c4ee-63f0-49a6-9b68-69625e5c6575",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "m8 = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp8 = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m8)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp8.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp8.geojson)\n",
    "\n",
    "  \n",
    "m8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee38a8",
   "metadata": {
    "id": "d8ee38a8"
   },
   "source": [
    "### k_district = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23c845",
   "metadata": {
    "id": "4f23c845",
    "outputId": "56fe46ca-1000-40a1-d13d-5178b9e2bc09"
   },
   "outputs": [],
   "source": [
    "k_district=6\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.5\n",
    "\n",
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)\n",
    "        \n",
    "model = Model(\"Taichung_re-distribution\")\n",
    "y_edges = {}\n",
    "\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')\n",
    "        \n",
    "# Add constraint yii\n",
    "expr = 0\n",
    "for center in G.nodes():\n",
    "    expr += y_edges[(center,center)]\n",
    "model.addConstr(expr == k_district)\n",
    "\n",
    "for center in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for edge in G.nodes():\n",
    "            tail_to_head += y_edges[(center,edge)]\n",
    "    model.addConstr(tail_to_head == 1)\n",
    "    \n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])\n",
    "        \n",
    "# Add constraint xii\n",
    "for center in G.nodes():\n",
    "    summary = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(edge,center)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(center,center)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(center,center)])\n",
    "    \n",
    "obj = 0\n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        obj += distance[(edge,cneter)]*y_edges[(edge,center)]\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "cluster_group = {}\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].X == 1:\n",
    "        cluster_group[center] = []\n",
    "    \n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].X == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            \n",
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a9c294",
   "metadata": {
    "id": "e8a9c294",
    "outputId": "2576aeb3-bf86-464d-de90-ebed79b85b08"
   },
   "outputs": [],
   "source": [
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)\n",
    "    \n",
    "cluster_group.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2928f5b4",
   "metadata": {
    "id": "2928f5b4"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3179f7",
   "metadata": {
    "id": "0a3179f7",
    "outputId": "268b6817-5c33-4e0e-fc9f-003d0081f27f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "m6 = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp6 = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m6)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp6.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp6.geojson)\n",
    "\n",
    "  \n",
    "m6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a6886e",
   "metadata": {
    "id": "26a6886e"
   },
   "source": [
    "### k_district = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce818c",
   "metadata": {
    "id": "e4ce818c",
    "outputId": "4c240114-fc3f-4869-cd7c-e38ca6847eff"
   },
   "outputs": [],
   "source": [
    "k_district=5\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.5\n",
    "\n",
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)\n",
    "        \n",
    "model = Model(\"Taichung_re-distribution\")\n",
    "y_edges = {}\n",
    "\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')\n",
    "        \n",
    "# Add constraint yii\n",
    "expr = 0\n",
    "for center in G.nodes():\n",
    "    expr += y_edges[(center,center)]\n",
    "model.addConstr(expr == k_district)\n",
    "\n",
    "for center in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for edge in G.nodes():\n",
    "            tail_to_head += y_edges[(center,edge)]\n",
    "    model.addConstr(tail_to_head == 1)\n",
    "    \n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])\n",
    "        \n",
    "# Add constraint xii\n",
    "for center in G.nodes():\n",
    "    summary = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(edge,center)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(center,center)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(center,center)])\n",
    "    \n",
    "obj = 0\n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        obj += distance[(edge,center)]*y_edges[(edge,center)]\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "cluster_group = {}\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].X == 1:\n",
    "        cluster_group[center] = []\n",
    "    \n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].X == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            \n",
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0871f0",
   "metadata": {
    "id": "ba0871f0",
    "outputId": "eabae1c8-c44f-4890-95e2-bf22be731d8b"
   },
   "outputs": [],
   "source": [
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)\n",
    "    \n",
    "cluster_group.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dbdab5",
   "metadata": {
    "id": "d5dbdab5"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a521e76",
   "metadata": {
    "id": "8a521e76",
    "outputId": "fc7a153f-7e0f-4112-aece-7a63ffc7ac06",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "m5 = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp5 = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m5)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp5.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp5.geojson)\n",
    "\n",
    "  \n",
    "m5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c450ac7",
   "metadata": {
    "id": "0c450ac7"
   },
   "source": [
    "### k_district = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc345f",
   "metadata": {
    "id": "2cbc345f",
    "outputId": "978889e7-5038-4d22-899c-bc9985b406df"
   },
   "outputs": [],
   "source": [
    "k_district=4\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.5\n",
    "\n",
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)\n",
    "        \n",
    "model = Model(\"Taichung_re-distribution\")\n",
    "y_edges = {}\n",
    "\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')\n",
    "        \n",
    "# Add constraint yii\n",
    "expr = 0\n",
    "for center in G.nodes():\n",
    "    expr += y_edges[(center,center)]\n",
    "model.addConstr(expr == k_district)\n",
    "\n",
    "for center in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for edge in G.nodes():\n",
    "            tail_to_head += y_edges[(center,edge)]\n",
    "    model.addConstr(tail_to_head == 1)\n",
    "    \n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])\n",
    "        \n",
    "# Add constraint xii\n",
    "for center in G.nodes():\n",
    "    summary = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(edge,center)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(center,center)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(center,center)])\n",
    "    \n",
    "obj = 0\n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        obj += distance[(edge,center)]*y_edges[(edge,center)]\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "cluster_group = {}\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].X == 1:\n",
    "        cluster_group[center] = []\n",
    "    \n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].X == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            \n",
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512fe84",
   "metadata": {
    "id": "2512fe84",
    "outputId": "f4e49d0f-93da-430a-94a7-f94918aaa43d"
   },
   "outputs": [],
   "source": [
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)\n",
    "    \n",
    "cluster_group.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340c5c2",
   "metadata": {
    "id": "5340c5c2"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e78d48",
   "metadata": {
    "id": "79e78d48",
    "outputId": "b518362f-69ad-40df-ce19-9c4013673e1c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "m4 = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp4 = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m4)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp4.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp4.geojson)\n",
    "\n",
    "  \n",
    "m4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a53dd4",
   "metadata": {
    "id": "97a53dd4"
   },
   "source": [
    "### k_district = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65934a",
   "metadata": {
    "id": "cb65934a",
    "outputId": "5e55eb82-d4bd-4673-b089-3e228dc5be2c"
   },
   "outputs": [],
   "source": [
    "k_district=3\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.5\n",
    "\n",
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)\n",
    "        \n",
    "model = Model(\"Taichung_re-distribution\")\n",
    "y_edges = {}\n",
    "\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')\n",
    "        \n",
    "# Add constraint yii\n",
    "expr = 0\n",
    "for center in G.nodes():\n",
    "    expr += y_edges[(center,center)]\n",
    "model.addConstr(expr == k_district)\n",
    "\n",
    "for center in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for edge in G.nodes():\n",
    "            tail_to_head += y_edges[(center,edge)]\n",
    "    model.addConstr(tail_to_head == 1)\n",
    "    \n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])\n",
    "        \n",
    "# Add constraint xii\n",
    "for center in G.nodes():\n",
    "    summary = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(edge,center)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(center,center)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(center,center)])\n",
    "    \n",
    "obj = 0\n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        obj += distance[(edge,center)]*y_edges[(edge,center)]\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "cluster_group = {}\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].X == 1:\n",
    "        cluster_group[center] = []\n",
    "    \n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].X == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            \n",
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f68b7f",
   "metadata": {
    "id": "27f68b7f",
    "outputId": "6535dcf1-7dbb-41a5-d67c-cd0f9cd4ac6a"
   },
   "outputs": [],
   "source": [
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)\n",
    "    \n",
    "cluster_group.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1711d8",
   "metadata": {
    "id": "8b1711d8"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98df339",
   "metadata": {
    "id": "c98df339",
    "outputId": "68345e0b-812c-4e9f-bbb7-c70ffec72cbf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "m3 = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp3 = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m3)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp5.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp3.geojson)\n",
    "\n",
    "  \n",
    "m3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d20be",
   "metadata": {
    "id": "ba2d20be"
   },
   "source": [
    "### k_district = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef27fc0",
   "metadata": {
    "id": "1ef27fc0",
    "outputId": "7c38ba5b-0822-46dd-9e88-858ec6e7c49e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_district=2\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.5\n",
    "\n",
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)\n",
    "        \n",
    "model = Model(\"Taichung_re-distribution\")\n",
    "y_edges = {}\n",
    "\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')\n",
    "        \n",
    "# Add constraint yii\n",
    "expr = 0\n",
    "for center in G.nodes():\n",
    "    expr += y_edges[(center,center)]\n",
    "model.addConstr(expr == k_district)\n",
    "\n",
    "for center in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for edge in G.nodes():\n",
    "            tail_to_head += y_edges[(center,edge)]\n",
    "    model.addConstr(tail_to_head == 1)\n",
    "    \n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])\n",
    "        \n",
    "# Add constraint xii\n",
    "for center in G.nodes():\n",
    "    summary = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(edge,center)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(center,center)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(center,center)])\n",
    "    \n",
    "obj = 0\n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        obj += distance[(edge,center)]*y_edges[(edge,center)]\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "model.optimize()\n",
    "\n",
    "\n",
    "cluster_group = {}\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].X == 1:\n",
    "        cluster_group[center] = []\n",
    "    \n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].X == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            \n",
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db733c3",
   "metadata": {
    "id": "5db733c3",
    "outputId": "36f16d88-e354-4053-ba32-79940da0f55a"
   },
   "outputs": [],
   "source": [
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)\n",
    "    \n",
    "cluster_group.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777c501",
   "metadata": {
    "id": "f777c501"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca68eb2",
   "metadata": {
    "id": "fca68eb2",
    "outputId": "7a0deddc-3bd6-4611-8831-ded9f7d6c516",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "m2 = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp2 = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m2)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp2.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp2.geojson)\n",
    "\n",
    "  \n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f7e0d",
   "metadata": {
    "id": "8a2f7e0d"
   },
   "source": [
    "\n",
    "### Comparison: True to Taichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebc8ea",
   "metadata": {
    "id": "beebc8ea"
   },
   "outputs": [],
   "source": [
    "k_district=8\n",
    "data3 = data.copy()\n",
    "data3[\"legislator_district\"] = data[\"legislator_district\"]\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data3[\"legislator_district\"]:\n",
    "    for center in range(len(list(set(data3.legislator_district)))):\n",
    "        if edge == list(set(data3.legislator_district))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data3[\"legislator_district\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df08914",
   "metadata": {
    "id": "5df08914",
    "outputId": "3264dfdf-1e44-49ef-87c5-374dfd80d0f6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mapping scale. Define the scale into ten divisions\n",
    "custom_scale = list(np.linspace(min(data3[\"legislator_district\"]), max(data3[\"legislator_district\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "\n",
    "m_comparison = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp_comparison = folium.Choropleth(\n",
    "    data=data3,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'legislator_district'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m_comparison)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp_comparison.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data3.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data3.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data3.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data3.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['legislator_district'] = str(data3.loc[s[\"properties\"][\"T_Name\"], 'legislator_district'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", 'bias', \"legislator_district\" ]).add_to(cp_comparison.geojson)\n",
    "\n",
    "  \n",
    "m_comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db9c40d",
   "metadata": {
    "id": "1db9c40d"
   },
   "source": [
    "## Chapter 4 : problem 2-- Gerrymandering to benefit the winner(The Dpp party)<a name=\"Dpp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007cca1",
   "metadata": {
    "id": "9007cca1"
   },
   "outputs": [],
   "source": [
    "## G=nx.Graph()\n",
    "node_tuple = [(0,1),(0,3),(0,16),(0,24),(1,2),(1,13),(1,16),(1,24),(1,25),(2,12),(2,13),(2,14),(2,20),(2,25),(2,26),\n",
    "              (3,4),(3,11),(3,16),(3,21),(3,24),(4,10),(4,21),(4,24),(4,25),(5,7),(5,15),(5,19),(5,23),(5,26),\n",
    "              (6,14),(6,15),(7,9),(7,19),(7,23),(8,9),(8,19),(9,19),(10,21),(10,25),(10,28),(11,13),(11,16),(11,21),(11,27),\n",
    "              (12,18),(12,19),(12,20),(12,23),(12,25),(13,14),(13,16),(13,27),(14,15),(14,22),(14,26),(15,22),(15,26),(16,24),\n",
    "              (17,18),(17,19),(17,28),(18,19),(18,23),(18,25),(18,28),(19,23),(20,23),(20,26),(21,27),(22,26),(23,26),\n",
    "              (24,25),(25,28)]\n",
    "G.add_edges_from(node_tuple)\n",
    "\n",
    "\n",
    "for i,d in G.nodes(data = True):\n",
    "    for j in range(data.shape[0]):\n",
    "        if data.iloc[j,0] == i: ## if data node equal to the G.node\n",
    "            d[\"sum\"] = data.iloc[j,5]\n",
    "            d[\"bias\"] = data.iloc[j,4]\n",
    "\n",
    "\n",
    "\n",
    "k_district=3\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4de245",
   "metadata": {
    "id": "4c4de245",
    "outputId": "fa439029-460e-40f7-bf6f-a48e5b89d2eb"
   },
   "outputs": [],
   "source": [
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)\n",
    "        \n",
    "        \n",
    "        \n",
    "model = Model(\"Bias-Dpp\")\n",
    "y_edges = {}\n",
    "win = {}\n",
    "   \n",
    "      \n",
    "        \n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')\n",
    "        \n",
    "\n",
    "## Create variables win[center] to record how many legislator district DPP win\n",
    "for center in G.nodes():\n",
    "    win[center] = model.addVar(vtype=GRB.BINARY, name='win('+str(center)+')')\n",
    "        \n",
    "expr = 0\n",
    "for center in G.nodes():\n",
    "    expr += y_edges[(center,center)]\n",
    "model.addConstr(expr == k_district)\n",
    "\n",
    "\n",
    "\n",
    "for center in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for edge in G.nodes():\n",
    "            tail_to_head += y_edges[(center,edge)]\n",
    "    model.addConstr(tail_to_head == 1)\n",
    "    \n",
    "    \n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])\n",
    "            \n",
    "            \n",
    "            \n",
    "for center in G.nodes():\n",
    "    summary = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(edge,center)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(center,center)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(center,center)])\n",
    "\n",
    "\n",
    "## in each center node, the Dpp win variable(win[center]) should be less than or equal to it comparately center node\n",
    "for center in G.nodes():\n",
    "    model.addConstr(win[center] <= y_edges[(center,center)]) \n",
    "\n",
    "## Control center node, the overall bias summary multiply with win should be equal or large than 0\n",
    "for center in G.nodes():\n",
    "    bias_sum = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "        bias_sum += d1[\"bias\"]*win[center]*y_edges[(edge,center)]\n",
    "    model.addConstr(bias_sum >= 0)\n",
    "        \n",
    "\n",
    "    \n",
    "obj = 0\n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "        obj += distance[(edge,center)]*y_edges[(edge,center)]\n",
    "for edge in range(2,k_district):\n",
    "    if k_district == 2:\n",
    "        model.addConstr(obj <= 42)\n",
    "    elif k_district ==3:\n",
    "        model.addConstr(obj <= 32)\n",
    "    elif k_district == 7:\n",
    "        model.addConstr(obj <= 22)\n",
    "# model.setObjective(obj, GRB.MINIMIZE)\n",
    "model.addConstr(obj <= 32)\n",
    "\n",
    "obj2 = 0\n",
    "for center in G.nodes():\n",
    "    obj2 += win[center]\n",
    "model.setObjective(obj2, GRB.MAXIMIZE)\n",
    "# model.setObjective(obj2, GRB.MINIMIZE)\n",
    "     \n",
    "\n",
    "model.write(\"test3.lp\")\n",
    "model.optimize()\n",
    "print(obj.getValue())\n",
    "print(obj2.getValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be20c0f6",
   "metadata": {
    "id": "be20c0f6",
    "outputId": "a8cb74aa-8c50-44ba-b6b5-255dbed1acb9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_group = {}\n",
    "\n",
    "print(\"Win district center node:\")\n",
    "for center in G.nodes():\n",
    "    if win[center].X == 1:\n",
    "        print(win[center])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Center nodes:\")\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].X == 1:\n",
    "        cluster_group[center] = []\n",
    "        print(y_edges[(center),center])\n",
    "print(\"\\n\")\n",
    "    \n",
    "print(\"Edge nodes:\")\n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].X == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            print(y_edges[(edge,center)])\n",
    "print(\"\\n\")\n",
    "            \n",
    "print(\"Each district population:\")\n",
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop  \n",
    "print(summary_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb4631f",
   "metadata": {
    "id": "9cb4631f",
    "outputId": "983f6ea9-6a22-40bc-9187-04427301e63b"
   },
   "outputs": [],
   "source": [
    "sum_bias = {}\n",
    "for key in cluster_group.keys():\n",
    "    sum_bias[key] = 0\n",
    "    for node in cluster_group[key]:\n",
    "        for edge,d1 in G.nodes(data = True):\n",
    "            if node == edge:\n",
    "                sum_bias[key] += d1[\"bias\"]\n",
    "sum_bias          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973df33",
   "metadata": {
    "id": "1973df33",
    "outputId": "4c074828-465a-4bcd-e46b-bcca34d184b8"
   },
   "outputs": [],
   "source": [
    "cluster_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed862a07",
   "metadata": {
    "id": "ed862a07",
    "outputId": "0d58c922-d102-4125-dda1-a7be026f0178"
   },
   "outputs": [],
   "source": [
    "##### nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100006a",
   "metadata": {
    "id": "6100006a"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfda840",
   "metadata": {
    "id": "bbfda840"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe47dfc",
   "metadata": {
    "id": "ebe47dfc",
    "outputId": "65bfd3a3-1be6-4408-81a8-140042036804",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "m7_DPP = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp7_DPP = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m7_DPP)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp7_DPP.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp7_DPP.geojson)\n",
    "\n",
    "  \n",
    "m7_DPP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff971c4a",
   "metadata": {
    "id": "ff971c4a"
   },
   "source": [
    "## Chapter 5: problem 3-- Gerrymandering to benefit the loser(The KMT party)<a name=\"KMT\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c229e031",
   "metadata": {
    "id": "c229e031"
   },
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "node_tuple = [(0,1),(0,3),(0,16),(0,24),(1,2),(1,13),(1,16),(1,24),(1,25),(2,12),(2,13),(2,14),(2,20),(2,25),(2,26),\n",
    "              (3,4),(3,11),(3,16),(3,21),(3,24),(4,10),(4,21),(4,24),(4,25),(5,7),(5,15),(5,19),(5,23),(5,26),\n",
    "              (6,14),(6,15),(7,9),(7,19),(7,23),(8,9),(8,19),(9,19),(10,21),(10,25),(10,28),(11,13),(11,16),(11,21),(11,27),\n",
    "              (12,18),(12,19),(12,20),(12,23),(12,25),(13,14),(13,16),(13,27),(14,15),(14,22),(14,26),(15,22),(15,26),(16,24),\n",
    "              (17,18),(17,19),(17,28),(18,19),(18,23),(18,25),(18,28),(19,23),(20,23),(20,26),(21,27),(22,26),(23,26),\n",
    "              (24,25),(25,28)]\n",
    "G.add_edges_from(node_tuple)\n",
    "\n",
    "\n",
    "for i,d in G.nodes(data = True):\n",
    "    for j in range(data.shape[0]):\n",
    "        if data.iloc[j,0] == i: ## if data node equal to the G.node\n",
    "            d[\"sum\"] = data.iloc[j,5]\n",
    "            d[\"bias\"] = data.iloc[j,4]\n",
    "\n",
    "\n",
    "\n",
    "k_district=7\n",
    "avg_pop = sum(data[\"sum\"])/k_district\n",
    "tolerance = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd4d1a",
   "metadata": {
    "id": "02dd4d1a",
    "outputId": "2acda9e4-e5fc-488a-cad1-291ddffa05c3"
   },
   "outputs": [],
   "source": [
    "distance = {}\n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        distance[(i,j)] = nx.shortest_path_length(G, i, j)\n",
    "        \n",
    "        \n",
    "        \n",
    "model = Model(\"Bias-KMT\")\n",
    "y_edges = {}\n",
    "win = {}\n",
    "   \n",
    "      \n",
    "        \n",
    "for i in G.nodes():\n",
    "    for j in G.nodes():\n",
    "        y_edges[(i,j)] =model.addVar(vtype=GRB.BINARY, name='y_edges('+str(i)+','+str(j)+')')\n",
    "        \n",
    "\n",
    "## Create variables win[center] to record how many legislator district DPP win\n",
    "for center in G.nodes():\n",
    "    win[center] = model.addVar(vtype=GRB.BINARY, name='win('+str(center)+')')\n",
    "        \n",
    "expr = 0\n",
    "for edge in G.nodes():\n",
    "    expr += y_edges[(edge,edge)]\n",
    "model.addConstr(expr == k_district)\n",
    "\n",
    "\n",
    "\n",
    "for edge in G.nodes():\n",
    "    tail_to_head = 0\n",
    "    for center in G.nodes():\n",
    "            tail_to_head += y_edges[(edge,center)]\n",
    "    model.addConstr(tail_to_head == 1)\n",
    "    \n",
    "    \n",
    "for center in G.nodes():\n",
    "    for edge in G.nodes():\n",
    "            model.addConstr(y_edges[(edge,center)] <= y_edges[(center,center)])\n",
    "            \n",
    "            \n",
    "            \n",
    "for center in G.nodes():\n",
    "    summary = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "            summary += y_edges[(edge,center)]*d1[\"sum\"]\n",
    "    model.addConstr(summary <= avg_pop*(1 + tolerance)*y_edges[(center,center)])\n",
    "    model.addConstr(summary >= avg_pop*(1 - tolerance)*y_edges[(center,center)])\n",
    "\n",
    "    \n",
    "\n",
    "## in each center node, the Dpp win variable(win[center]) should be less than or equal to it comparately center node\n",
    "for center in G.nodes():\n",
    "    model.addConstr(win[center] <= y_edges[(center,center)]) \n",
    "\n",
    "## Control center node, the overall bias summary multiply with win should be equal or large than 0\n",
    "for center in G.nodes():\n",
    "    bias_sum = 0\n",
    "    for edge,d1 in G.nodes(data = True):\n",
    "        bias_sum += d1[\"bias\"]*win[center]*y_edges[(edge,center)]\n",
    "    model.addConstr(bias_sum <= 0)\n",
    "        \n",
    "\n",
    "    \n",
    "obj = 0\n",
    "for center in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        obj += distance[(edge,center)]*y_edges[(edge,center)]\n",
    "model.addConstr(obj <= 22)\n",
    "\n",
    "obj2 = 0\n",
    "for center in G.nodes():\n",
    "    obj2 += win[center]\n",
    "model.setObjective(obj2, GRB.MAXIMIZE)\n",
    "     \n",
    "\n",
    "model.write(\"test3.lp\")\n",
    "model.optimize()\n",
    "print(obj.getValue())\n",
    "print(obj2.getValue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3de88",
   "metadata": {
    "id": "37b3de88",
    "outputId": "55b02824-bc55-4cb1-ba67-0c43a39cce39",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_group = {}\n",
    "\n",
    "print(\"Win district center node:\")\n",
    "for center in G.nodes():\n",
    "    if win[center].X == 1:\n",
    "        print(win[center])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Center nodes:\")\n",
    "for center in G.nodes():\n",
    "    if y_edges[(center,center)].X == 1:\n",
    "        cluster_group[center] = []\n",
    "        print(y_edges[(center,center)])\n",
    "print(\"\\n\")\n",
    "    \n",
    "print(\"Edge nodes:\")\n",
    "for edge in G.nodes():\n",
    "    for center in G.nodes():\n",
    "        if y_edges[(edge,center)].X == 1:\n",
    "            cluster_group[center].append(edge)\n",
    "            print(y_edges[(edge,center)])\n",
    "print(\"\\n\")\n",
    "            \n",
    "print(\"Each district population:\")\n",
    "summary_pop = {}\n",
    "for center in cluster_group:\n",
    "    local_pop = 0\n",
    "    for k in cluster_group[center]:\n",
    "        for edge,d in G.nodes(data = True):\n",
    "            if edge == k:\n",
    "                local_pop += d[\"sum\"]\n",
    "    summary_pop[center] = local_pop  \n",
    "print(summary_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad9725",
   "metadata": {
    "id": "46ad9725",
    "outputId": "225adbd2-3e8c-47ac-a36e-bdc75e40b45e"
   },
   "outputs": [],
   "source": [
    "sum_bias = {}\n",
    "for key in cluster_group.keys():\n",
    "    sum_bias[key] = 0\n",
    "    for node in cluster_group[key]:\n",
    "        for edge,d1 in G.nodes(data = True):\n",
    "            if node == edge:\n",
    "                sum_bias[key] += d1[\"bias\"]\n",
    "sum_bias          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5161055c",
   "metadata": {
    "id": "5161055c",
    "outputId": "27d4b6a3-ce25-4553-9c89-25b8fbdaf509"
   },
   "outputs": [],
   "source": [
    "cluster_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2377b",
   "metadata": {
    "id": "ecf2377b",
    "outputId": "f1902dcd-ca6f-4110-b39e-ffb32472f2de"
   },
   "outputs": [],
   "source": [
    "nx.draw(G,pos, with_labels=True, node_size=500,  node_color='yellow', alpha = 0.9, edge_color = \"black\", width=0.1)\n",
    "color = [\"red\", \"gold\", \"greenyellow\", \"blue\", \"purple\", \"darkviolet\", \"deeppink\", \"crimson\", \"black\", \"turquoise\"]\n",
    "for cluster in range(len(list(cluster_group.keys()))):\n",
    "    H = G.subgraph(cluster_group[list(cluster_group.keys())[cluster]])\n",
    "    T = nx.minimum_spanning_tree(H)\n",
    "    ered=[(edge,center) for (edge,center) in T.edges()] \n",
    "    nx.draw_networkx_edges(G,pos,edgelist=ered, edge_color=color[cluster], width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92b993",
   "metadata": {
    "id": "2c92b993"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74d9d0",
   "metadata": {
    "id": "2a74d9d0"
   },
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1[\"classification\"] = 0\n",
    "\n",
    "for edge in range(data1.shape[0]):\n",
    "    for center in list(cluster_group.keys()):\n",
    "        if data1[\"node\"][edge] in cluster_group[center]:\n",
    "            data1[\"classification\"][edge] = center\n",
    "\n",
    "re_set_class = []\n",
    "for edge in data1[\"classification\"]:\n",
    "    for center in range(len(list(set(data1.classification)))):\n",
    "        if edge == list(set(data1.classification))[center]:\n",
    "            re_set_class.append((center+1)/k_district)\n",
    "            \n",
    "data1[\"classification\"] = re_set_class\n",
    "del re_set_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0fd18",
   "metadata": {
    "id": "b7a0fd18",
    "outputId": "b4c1a034-ecb2-4d0d-d76f-0d748de7daad",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mapping scale. I define the scale into ten division\n",
    "custom_scale = list(np.linspace(min(data1[\"classification\"]), max(data1[\"classification\"]), k_district+1, endpoint = True))\n",
    "\n",
    "\n",
    "m7_KMT = folium.Map([24.21 ,120.98],tiles='Stamen Terrain',     \n",
    "                        zoom_start=10,\n",
    "                        width=\"%80\",\n",
    "                        height=\"%80\")\n",
    "                \n",
    "# Mapping parameters\n",
    "# Mapping parameters\n",
    "cp7_KMT = folium.Choropleth(\n",
    "    data=data1,\n",
    "    geo_data=Taichung_json,\n",
    "    nan_fill_color=\"black\",\n",
    "    line_weight=2,\n",
    "    fill_color='RdYlBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.5,\n",
    "    threshold_scale=custom_scale,\n",
    "    name = Taichung_by_district[\"district\"],\n",
    "    columns=['district', 'classification'],   \n",
    "    legend_name='2018 Taichung legislation distribution k = {}.'.format(k_district),\n",
    "    key_on='feature.properties.T_Name'\n",
    "    ).add_to(m7_KMT)\n",
    "\n",
    "\n",
    "# Indexes marking reference: https://stackoverflow.com/questions/70471888/text-as-tooltip-popup-or-labels-in-folium-choropleth-geojson-polygons\n",
    "for s in cp7_KMT.geojson.data['features']:\n",
    "    s['properties']['bias'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'bias'])\n",
    "    s['properties']['sum'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'sum'])\n",
    "    s['properties']['node'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'node'])\n",
    "    s['properties']['translation'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'translation'])\n",
    "    s['properties']['classification'] = str(data1.loc[s[\"properties\"][\"T_Name\"], 'classification'])\n",
    "\n",
    "\n",
    "# Mark indexes onto the map\n",
    "folium.GeoJsonTooltip([\"translation\", 'T_Name', \"node\", \"sum\", \"bias\", \"classification\" ]).add_to(cp7_KMT.geojson)\n",
    "\n",
    "  \n",
    "m7_KMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f63d5",
   "metadata": {
    "id": "735f63d5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
